<!DOCTYPE html>
<html><title>Variable length unaligned bytecode ⁑ Dernocua</title><meta charset="utf-8"></meta><link href="../liabilities/style.css" rel="stylesheet"></link><meta content="width=device-width, initial-scale=1.0" name="viewport"></meta><h1>Variable length unaligned bytecode</h1><div class="metadata">Kragen Javier Sitaker, 02021-03-02 (updated 02021-03-03)
(4 minutes)</div><p>Instruction set design for hardware has a different value system from
instruction set design for software emulation; sometimes the tradeoffs
that improve an instruction set for hardware implementation worsen it
for software.</p>
<p>For example, for software emulation, instructions trailed with
variable-length operands, like the 8086, are no problem, and
inconsistency from one instruction encoding to the next is no problem,
but bitfields are a terrible problem.  For hardware, bitfields are
just wires, but layout inconsistency adds layers of multiplexor delay;
for software, bitfields require bit shifting, which requires a loop if
your CPU lacks a barrel shifter or has registers too short for the
numbers you’re shifting.</p>
<p>I was prototyping a virtual machine in C today on my phone, using an
unsigned byte array as the VM’s memory.  I was pleased to see that
clang supports GCC’s pointers-to-labels extension and generates decent
code for it; my <code>goto dispatch;</code> at the end of each case even resulted
in duplicating the code <code>dispatch: goto *tbl[mem[pc++]];</code> in every
case, which is one or another variant of</p>
<pre><code>ldrb r2, [r4, r6]
add r1, r6, #1
ldr r3, [r5, r2, lsl #1]
bx r3
</code></pre>
<p>Duplicating this code allows each case to have its own BTB entry,
which is helpful for branch prediction, and saves a wasteful
unconditional jump.  So, the virtual machine bytecode dispatch
overhead is only about a factor of 5, and all seemed good in the
world.  But then I looked at unaligned memory access.</p>
<p>My code to store a 32-bit value in the memory was:</p>
<pre><code>#define byt(x) ((x) &amp; 255)
#define store_tet(val, p) do { \
        mem[p] = byt(val); \
        mem[(p)+1] = byt((val) &gt;&gt; 8); \
        mem[(p)+2] = byt((val) &gt;&gt; 16); \
        mem[(p)+3] = byt((val) &gt;&gt; 24); \
} while (0)
</code></pre>
<p>I figured that this was a portable, #ifdef-free way of marshalling a
little-endian 32-bit value, but the phone’s ARM processor (a Qualcomm
MSM8939 ARMv7l) is running in little-endian mode, so Clang would
recognize this and convert it to a simple store.  Imagine my surprise
at seeing the assembly:</p>
<pre><code>strb r7, [r4, #3]
strb r7, [r4, #2]
strb r7, [r4, #1]
strb r7, [r4]
</code></pre>
<p><a href="https://archive.fo/aWFc7">ARMv7 supports unaligned access</a> but possibly the compiler is not
generating ARMv7 code; it’s not using Thumb, for example, although
/proc/cpuinfo says it’s supported.  (<code>-march=armv7</code> doesn’t help.)
(Older ARM versions mostly ignored the low-order bits, but had strange
behavior in <code>ldr</code> and unpredictable behavior in <code>ldrh</code> and <code>ldrd</code>.
<a href="https://archive.fo/kDlnI">ARMv11 has an even larger set of possibilities</a>.)  But there’s an
option in ARMv7 to trap on unaligned accesses!  So you can’t rely on
it.  Also, as a side note, it doesn’t seem to be doing the specified
bit shifts; in other cases it says things like</p>
<pre><code>lsr r0, r3, #24
...
strb r0, [r1, #-1]
lsr r0, r3, #16
strb r0, [r1, #-2]
lsr r0, r3, #8
strb r0, [r1, #-3]
</code></pre>
<p>which is sort of reasonable, although I’m not sure what happened to
r3’s least significant byte.  Except it’s <em>not</em> reasonable: a single
virtual machine instruction to store a 32-bit value in RAM is going to
take 7 instructions on the underlying machine this way, plus dispatch
overhead.</p>
<p>So I was happily replacing my byte array with an array of <code>uint32_t</code>
(it’s a prototype!  I can do things like that!) and started using
<code>mem[p/4]</code> and <code>byt(mem[p/4] &gt;&gt; (p &amp; 3))</code> before I realized that I’d
just replicated the whole unaligned-memory-access problem.  If an
instruction contains an unaligned 4-byte immediate operand, rounding
down <code>p/4</code> is not going to fetch that immediate successfully!</p>
<p>So, unless I’m going to require the instructions to be aligned, which
probably means mostly not using variable-length instructions, the
multiple shifts and loads are going to be happening.  Even if you have
“hardware support” for unaligned accesses, that doesn’t mean you
aren’t paying a speed penalty, or that it’s less than the above
code — it might be implemented by trapping to the kernel, making it
hundreds of times slower.</p>
<p>So this is a case where I thought hardware and software were more
different than they actually are.</p><script src="../liabilities/addtoc.js"></script><div><h2>Topics</h2><ul><li><a href="../topics/performance.html">Performance</a> (22 notes)
</li><li><a href="../topics/asm.html">Assembly-language programming</a> (11 notes)
</li><li><a href="../topics/virtual-machines.html">Virtual machines</a> (9 notes)
</li><li><a href="../topics/instruction-sets.html">Instruction sets</a> (6 notes)
</li><li>The ARM Acorn RISC Machine</li></ul></div></html>